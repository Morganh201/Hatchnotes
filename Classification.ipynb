{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee0dce3f",
   "metadata": {},
   "source": [
    "# Supervised Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c551a5db",
   "metadata": {},
   "source": [
    "There are two types of machine learning problems: classification and regression. Regression deals with predicting numerical values, where the range of values is continuous, while classification problems deal with predicting categorical, or discrete values. For example, using classification, we can predict whether or not a person from the titanic survives or not. There are two types of learners in machine learning classification: lazy and eager learners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f7ac19",
   "metadata": {},
   "source": [
    "**Eager learners** are algorithms that build a model from the training dataset before making any predictions on any future datasets. They learn to get a better generalization of the weights during training, and thus make predictions quickly. **Lazy learners** are algorithms that do not learn anything from the training set, but they instead memorize the training data and when they need to make predictions, they look for the nearest neighbor to make the prediction, and thus make predictions slowly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eee064",
   "metadata": {},
   "source": [
    "There are four main classification tasks in Machine Learning: binary, multi-class, multi-label, and imbalanced classifications. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f413a",
   "metadata": {},
   "source": [
    "In a **binary classification**, we have two options for output; either one option or the other. Some machine learning algorithms designed for binary classification are **logistic regression and support vector machines**. In **multi-class classification**, it follows that there are more than two options for output. Some algorithms designed for multi-class classification is **random forests, naive bayes, k-nearest neighbors, gradient boosting, SVM(support vector machines), and logistic regression**. Note that binary classification methods can be used in multi-class classification, through techniques such as one-versus-one and one-versus-all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1057e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of logistic regression\n",
    "# Given n variables, and an output with values of either 0 or 1, we plot the points in n-dimensional space, and perform\n",
    "# linear regression through finding the line of best fit(minimizing the vertical error), then we transform the equation of the \n",
    "# line into the sigmoid function, performing logistic regression. Logistic regression is best used when there is little \n",
    "# collinearity between variables\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(val_X)\n",
    "\n",
    "# An example of SVM\n",
    "# We plot the data points in terms of the feature values, then we organize them in terms of their categorical variable. We then \n",
    "# find the best line that has the greatest margin between the two categories, and thus through that line, we can determine\n",
    "# if a data point belongs to which category. If the two categories cannot be separated by a linear hyperplane, then we transform\n",
    "# the data into a higher dimension, thus we can create a seperable line. Experiment with polynomial, Gaussian, and sigmoid \n",
    "# kernels\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "predictions = svc.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "# We find the conditional probability P(C_i|x_1, ..., x_n) through Bayes theorem, where C_i is categorical variable and \n",
    "# x_i are features. The categorical variable with the highest conditional probability is the label the machine will give \n",
    "# to the input. We typically use naive bayes if the variables are independent of each other and have equal value to the result\n",
    "# Three types of naive bayes classifiers: Bernoulli(feature is either present or not), Multinomial(the frequency of the\n",
    "# feature), and Gaussian(feature data is continuous)\n",
    "\n",
    "# Example of Gaussian Naive Bayes(assumes that the data follows normal distribution)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "predictions = gnb.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07994f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests\n",
    "# Consists of a forest of many decision trees, each created randomly with random samples that has the same size as the\n",
    "# original dataset, and random features in each tree node. In addition, in each random sample, there is no replacement,\n",
    "# meaning that there might be duplicates, called a bootstrap sample. This ensures that every element in the sample is \n",
    "# independently distributed. Note that duplicates will be removed, by set theory. Each decision tree will output a result, \n",
    "# and the tree will output the average of all the results, or the result that holds the majority. \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=1000, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1546952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-nearest neighbors\n",
    "# Given a set of points graphs in terms of features and labels based on their target, when we are given a new data point, \n",
    "# it follows that through the algorithm, we find its k neighbors, and whichever class its closest neighbours are, that class\n",
    "# is given to that new point. Because we need to properly differentiate points, we must use feature engineering and feature \n",
    "# selection, which can also remove the problem of the curse of dimensionality, to make the model easier to group points\n",
    "# together based on their class\n",
    "\n",
    "# In addition, we must be able to optimally choose the number of neighbors we will use in the model to not cause over and \n",
    "# under fitting. For example, if we have a dataset that is prone to noise, it makes sense to have more neighbors. However, \n",
    "# too many neighbors can lead to underfitting the data, and vice versa. It is ideal to have an odd number of neighbours so that\n",
    "# there won't be any ties\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0914df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost(Extreme Gradient Boosting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe1fb09",
   "metadata": {},
   "source": [
    "To implement the one-versus-one technique, we have multiple classifiers. Each classifier will train the dataset based on two specific and distinct labels, and makes a decision at the end based on the majority vote. To implement the one-versus-rest, we also have multiple classifiers, each corresponds to a different label, and thus the computer will train the dataset based on that label against all the other labels, where all the other labels are represented as one label in the binary classification method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f060a5aa",
   "metadata": {},
   "source": [
    "In **multi-label classification**, we are predicting multiple labels in an input. This means that the output of the model can have multiple labels. Thus, multi-class and binary classification methods cannot be used to perform multi-label classification, although most algorithms have specilized versions for multi-label classification. For example, we have **multi-label decision trees, multi-label gradient boosting, and multi-label random forests**. Lastly, we have **imbalanced classification**, where the number of rows of data is unevenly distributed in each label, meaning that there will be more rows of data in one category than another. Using decision trees or logistic regression is not valid in this situation as there will be bias towards one category over another, and thus treat other categories as noise. In reality, almost all data is imbalanced, so we must consider these techniques in our machine learning application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb7b5e9",
   "metadata": {},
   "source": [
    "There are multiple techniques to solve the imbalance problem in the dataset. For example, we can use sampling techniques such as **cluster-based oversampling and random undersampling**, which is the process of random elimination of data from the majority class, and **SMOTE oversampling**, which is the process of random replication of data from the minority class(useful when there is a very big gap between classes). Another technique is to use cost-sensitive algorithms, which considers the cost of misclassification, such as **cost-sensitive decision trees, cost-sensitive logistic regression, and cost-sensitive support vector machines**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56e67940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of using random undersampling\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0, sampling_strategy='majority')\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# An example of using SMOTE oversampling\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e3855d",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d32443",
   "metadata": {},
   "source": [
    "There are many different types of methods to use when dealing with a classification problem. This is why we must evaluate each method, and choose the best algorithm so that we can solve the problem effectively. There are many different metrics to use when evaluating methods: Accuracy, precision, recall, F1 score, and area under the ROC(Receiver Operating Characteristic) curve and AUC(Area under the Curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948fb57e",
   "metadata": {},
   "source": [
    "**Accuracy** is the simplest metric to use, in the sense that we simply divide the number of correct predictions over the total number of predictions. However, it is prone to be misleading, especially when dealing with imbalanced data, and doesn't give us much information on the distribution of false information. **Precision** is the ratio of true positives against the total positives. It is useful when the dataset is skewed and unbalanced. **Recall** is the ratio of true positives to the total positives in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fce1db",
   "metadata": {},
   "source": [
    "It follows that the precision and recall are negatively correlated. That is, if our precision increases, it is likely that recall will decrease, and vice versa. To measure the relation between precision and recall, we use a metric called **f1 score**, which is the harmonic mean between both metrics. An f1 score of 1 means that the classifier has perfect precision and recall, while a score of 0 means that either precision or recall is equal to 0. We can modify the f1 score to favor either precision or recall, depending on the type of problem, by including a factor of $\\beta$. If $\\beta$ > 0, then the metric will favor recall, and if $\\beta$ < 0, then the metric will favor precision. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31941d6",
   "metadata": {},
   "source": [
    "A way to graphically see if the classifier is efficient or not is to use the **ROC(Receiver Operator Characteristic) curve**. The ROC curve plots the true positive rate(TPR), or the sensitivity, against the false positive rate(FPR), or the specificity, considering different threshold values. A threshold value is a value between 0 and 1 that determines whether or not the label is true or not. For example, after running through the machine learning model, if the probability of a label is over the threshold, then the label will be given to the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9cb054",
   "metadata": {},
   "source": [
    "Thus, any classifier with an ROC curve that has high TPR and low FPR is considered a good model. A good way to measure if the classifier performs well on the ROC metric is to measure the area under the ROC curve. The AUC ranges from 0 to 1, and if the AUC is over 0.5, then the method performs well on the ROC curve, and if it is under 0.5, then it is not good. The ROC-AUC metric is only good for balanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a61760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To evaluate metrics, we use the classification_report() function\n",
    "# from sklearn.metrics\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(val_X)\n",
    "classification_report(predictions, val_y)\n",
    "\n",
    "# Plotting the ROC curve, calculate area under the ROC curve\n",
    "from sklearn import metrics\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_train, predictions)\n",
    "auc = metrics.roc_auc_score(y_train, predictions)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"ROC curve\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53fcc6a",
   "metadata": {},
   "source": [
    "We can also visualize how many false positives or false negatives there are resulted by the model through the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106bef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(val_y, predictions)\n",
    "display = metrics.ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=[False, True])\n",
    "display.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
